{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**AssignmentNo. 6**\n",
        " Write a program to find the live weather report (temperature, wind speed, description, and weather) of a given city. (Python)."
      ],
      "metadata": {
        "id": "etpwEc2fP-tW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install requests\n",
        "import requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RGqzrd2VffY",
        "outputId": "33766bfa-b39e-4007-e614-7badc731fe39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68IJYkJrVbzN",
        "outputId": "7a9bea96-e453-4a0d-9b77-5491f6fa84ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Enter the city name: pune\n",
            "Weather in pune:\n",
            "Temperature: 27.15°C\n",
            "Wind Speed: 3.79 m/s\n",
            "Description: Overcast clouds\n",
            "Weather: Clouds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def get_weather(api_key, city):\n",
        "    base_url = \"http://api.openweathermap.org/data/2.5/weather\"\n",
        "\n",
        "    # Create a dictionary with parameters for the API request\n",
        "    params = {\n",
        "        \"q\": city,\n",
        "        \"appid\": api_key,\n",
        "        \"units\": \"metric\"  # Use metric units for temperature (Celsius)\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, params=params)\n",
        "        data = response.json()\n",
        "\n",
        "        # Check if the request was successful\n",
        "        if response.status_code == 200:\n",
        "            # Extract relevant weather information\n",
        "            temperature = data[\"main\"][\"temp\"]\n",
        "            wind_speed = data[\"wind\"][\"speed\"]\n",
        "            description = data[\"weather\"][0][\"description\"]\n",
        "            weather = data[\"weather\"][0][\"main\"]\n",
        "\n",
        "            print(f\"Weather in {city}:\")\n",
        "            print(f\"Temperature: {temperature}°C\")\n",
        "            print(f\"Wind Speed: {wind_speed} m/s\")\n",
        "            print(f\"Description: {description.capitalize()}\")\n",
        "            print(f\"Weather: {weather}\")\n",
        "        else:\n",
        "            print(\"Error: Unable to fetch weather data.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace 'your_api_key' with your actual OpenWeatherMap API key\n",
        "    api_key = \"5f5390f2a0a75c7a0a49b1609a73c596\"\n",
        "\n",
        "    city = input(\"Enter the city name: \")\n",
        "\n",
        "    get_weather(api_key, city)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SkoJmUq7QmSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bonpZGf_jtCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TZAjqbUgjs_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZIRwpwcijs8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wizo_sh9js5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gzRF5IE1js2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6JJpZRGhjszZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oCVXv1BpjswE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rjd8523zjss2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jwwTaCvpkEjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RLoHIIiTkQnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nP4HmP5IkEgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1vlF-2nEkEdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "du4z9z6rkEaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-DoGrCujsp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment No. 5**\n",
        " Build the web crawler to pull product information and links from an e-commerce website. (Python)"
      ],
      "metadata": {
        "id": "eA9xL6ySj6OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5xZMj9OQvD1",
        "outputId": "4b161679-da41-4ade-f5bd-be02f09e3948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "cwg6Z2-fRDYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the URL of the Flipkart search results page\n",
        "base_url = 'https://www.flipkart.com'\n",
        "search_query = 'bedshit'  # Your search query\n",
        "\n",
        "# Initialize an empty list to store the extracted data\n",
        "product_data = []\n",
        "\n",
        "def crawl_page(url):\n",
        "    try:\n",
        "        # Send an HTTP GET request to the URL\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Parse the HTML content of the page\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract product information and links\n",
        "        for product in soup.find_all('div', class_='_1AtVbE'):\n",
        "            product_name_elem = product.find('a', class_='IRpwTa')\n",
        "            product_price_elem = product.find('div', class_='_30jeq3')\n",
        "            product_link_elem = product.find('a', class_='IRpwTa')['href']\n",
        "\n",
        "            # Check if the elements exist before accessing their text\n",
        "            if product_name_elem and product_price_elem:\n",
        "                product_name = product_name_elem.text.strip()\n",
        "                product_price = product_price_elem.text.strip()\n",
        "                product_link = base_url + product_link_elem\n",
        "\n",
        "                product_data.append({\n",
        "                    'name': product_name,\n",
        "                    'price': product_price,\n",
        "                    'link': product_link\n",
        "                })\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Construct the search URL\n",
        "    search_url = f\"{base_url}/search?q={search_query}\"\n",
        "\n",
        "    # Crawl the search results page\n",
        "    crawl_page(search_url)\n",
        "\n",
        "    # Print the extracted data\n",
        "    for item in product_data:\n",
        "        print(f\"Product Name: {item['name']}\")\n",
        "        print(f\"Product Price: {item['price']}\")\n",
        "        print(f\"Product Link: {item['link']}\")\n",
        "        print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrTBPA-wWxlr",
        "outputId": "2469e3a4-80df-4eed-a980-381b7a7047b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: 429 Client Error: Too Many Requests for url: https://www.flipkart.com/search?q=bedshit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XH5QMHW6lAuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pprint import pprint\n",
        "def weather_data(query):\n",
        "  res = requests.get('http://api.openweathermap.org/data/2.5/weather?'+query+'&APPID=***********&&units=metric')\n",
        "  return res.json();\n",
        "def print_weather(result,city):\n",
        "  print(\"{}'s temperature: {}oC \".format(city,result['main']['temp']))\n",
        "  print(\"Wind speed:{}m/s\".format(result['wind']['speed']))\n",
        "  print(\"Description:{}\".format(result['weather'][0]['description']))\n",
        "  print(\"Weather:{}\".format(result['weather'][0]['main']))\n",
        "def main():\n",
        "  city = input('Enter the city: ')\n",
        "  print()\n",
        "  try:\n",
        "    query = 'q='+city;\n",
        "    w_data = weather_data(query);\n",
        "    print_weather(w_data, city)\n",
        "    print()\n",
        "  ecxept:\n",
        "    print('City name not found...')\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "id": "nw8WbOKZpN-I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}